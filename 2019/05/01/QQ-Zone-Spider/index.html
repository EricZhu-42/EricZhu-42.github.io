<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.1.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="前言功能简介本教程利用Python实现了一个简单的QQ空间说说抓取脚本。该脚本以每秒150~200条的速度抓取好友的历史说说，并将其格式化后存储至本地。">
<meta name="keywords" content="python">
<meta property="og:type" content="article">
<meta property="og:title" content="基于Python的多进程QQ空间爬虫">
<meta property="og:url" content="http://yoursite.com/2019/05/01/QQ-Zone-Spider/index.html">
<meta property="og:site_name" content="EricZhu-42&#39;s Blog">
<meta property="og:description" content="前言功能简介本教程利用Python实现了一个简单的QQ空间说说抓取脚本。该脚本以每秒150~200条的速度抓取好友的历史说说，并将其格式化后存储至本地。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2019/05/01/QQ-Zone-Spider/04.png">
<meta property="og:image" content="http://yoursite.com/2019/05/01/QQ-Zone-Spider/05.png">
<meta property="og:image" content="http://yoursite.com/2019/05/01/QQ-Zone-Spider/02.png">
<meta property="og:image" content="http://yoursite.com/2019/05/01/QQ-Zone-Spider/03.png">
<meta property="og:updated_time" content="2019-05-01T07:32:02.631Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="基于Python的多进程QQ空间爬虫">
<meta name="twitter:description" content="前言功能简介本教程利用Python实现了一个简单的QQ空间说说抓取脚本。该脚本以每秒150~200条的速度抓取好友的历史说说，并将其格式化后存储至本地。">
<meta name="twitter:image" content="http://yoursite.com/2019/05/01/QQ-Zone-Spider/04.png">





  
  
  <link rel="canonical" href="http://yoursite.com/2019/05/01/QQ-Zone-Spider/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>基于Python的多进程QQ空间爬虫 | EricZhu-42's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">EricZhu-42's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/01/QQ-Zone-Spider/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EricZhu-42">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EricZhu-42's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">基于Python的多进程QQ空间爬虫

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-01 11:51:55 / 修改时间：15:32:02" itemprop="dateCreated datePublished" datetime="2019-05-01T11:51:55+08:00">2019-05-01</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="功能简介"><a href="#功能简介" class="headerlink" title="功能简介"></a>功能简介</h3><p>本教程利用Python实现了一个简单的QQ空间说说抓取脚本。该脚本以每秒150~200条的速度抓取好友的历史说说，并将其格式化后存储至本地。</p>
<p><img src="/2019/05/01/QQ-Zone-Spider/04.png" alt="04"><br><img src="/2019/05/01/QQ-Zone-Spider/05.png" alt="04"></p>
<a id="more"></a>
<h3 id="环境需求"><a href="#环境需求" class="headerlink" title="环境需求"></a>环境需求</h3><ol>
<li>Python 3.72</li>
<li>Python模块：<a href="https://selenium-python.readthedocs.io/#" target="_blank" rel="noopener">Selenium</a> 与 <a href="http://cn.python-requests.org/zh_CN/latest/" target="_blank" rel="noopener">Requests</a></li>
<li>Google Chrome 74.0 与 ChromeDriver 74.0</li>
</ol>
<blockquote>
<p>注：具体版本号可酌情选择</p>
</blockquote>
<h2 id="你将在这里看到"><a href="#你将在这里看到" class="headerlink" title="你将在这里看到"></a>你将在这里看到</h2><ol>
<li>如何用Python实现对QQ空间说说数据的获取</li>
<li>如何利用Chrome<strong>开发者工具</strong>分析动态网页</li>
<li>如何利用Selenium完成对数据的请求与获取</li>
<li>如何在Requests与Selenium间传递参数(如<strong>Cookies</strong>)</li>
<li>如何完成一个简单的<strong>多进程爬虫</strong></li>
</ol>
<h2 id="你将不会在这里看到"><a href="#你将不会在这里看到" class="headerlink" title="你将不会在这里看到"></a>你将不会在这里看到</h2><ol>
<li><strong>如何安装</strong>Python、Python模块与ChromeDriver等开发环境</li>
<li><strong>过于基础</strong>的Python代码写法</li>
<li>Requests，Selenium，re，json等模块的<strong>详细介绍</strong></li>
<li>用Selenium实现<strong>自动登陆</strong>（然而以后可能会做）</li>
<li>关于Python与第三方模块的<strong>进阶用法</strong></li>
</ol>
<h2 id="关于思路的简单介绍"><a href="#关于思路的简单介绍" class="headerlink" title="关于思路的简单介绍"></a>关于思路的简单介绍</h2><p>首先，观察QQ空间说说页面，可以发现说说页面为<strong>动态网页</strong>，无法用下载网页并解析的方式获取说说数据。通过对翻页时发送/接收数据的分析，我们可以找出存放说说<strong>内容</strong>的具体<strong>文件</strong>与其<strong>请求方式</strong>。</p>
<p>其次，我们利用<strong>Selenium</strong>进行初步的模拟获取，成功地自动获取了说说内容页面，并对内容进行解析与格式化存储，速度为每秒20~40条。</p>
<p>接着，为了提高获取的效率，我们利用<strong>Requests</strong>与<strong>Multiprocessing</strong>，用<strong>多进程模式</strong>重构了脚本，使获取的速度提高为每秒150~200条。</p>
<p>最后，我们对脚本的<strong>功能</strong>进行完善，添加预计剩余时间，大文件分割等功能。</p>
<h2 id="网页内容分析"><a href="#网页内容分析" class="headerlink" title="网页内容分析"></a>网页内容分析</h2><blockquote>
<p>注：考虑到原项目的开发背景为对南京大学表白墙的数据分析，本文以“南京大学表白墙”为样例对象。</p>
</blockquote>
<h3 id="找到资源文件"><a href="#找到资源文件" class="headerlink" title="找到资源文件"></a>找到资源文件</h3><p>进入<a href="https://user.qzone.qq.com/2074934525/311" target="_blank" rel="noopener">目标的QQ空间说说页面</a>，<strong>查看网页源代码</strong>，我们可以发现说说内容并未保存在网页源文件中。因此，我们的获取目标为动态页面的数据内容。</p>
<blockquote>
<p>在动态页面中，数据内容一般在客户端与网页交互（如进入网页，点击翻页按钮）时发送到客户端，并通过JS脚本等途径动态插入到网页的&lt;div>标签中，从而完成对页面内容的更新。</p>
</blockquote>
<p>我们打开Chrome浏览器的<strong>开发者工具</strong>，切换到<strong>Network</strong>标签页。此时我们可以获得交互过程中加载的所有资源。为了减少干扰，我们点击Network标签页下的<strong>Clear</strong>按钮，并在说说页面中切换到下一页。</p>
<p><img src="/2019/05/01/QQ-Zone-Spider/02.png" alt="02"></p>
<p>右侧列表中列出了翻页过程中加载的资源。在排除了无关的图片文件后，我们可以发现说说内容保存在名称为<code>emotion_cgi_msglist_v6</code>的文件中。该文件即为我们要获得的说说数据。</p>
<p><img src="/2019/05/01/QQ-Zone-Spider/03.png" alt="03"></p>
<h3 id="找到请求模式"><a href="#找到请求模式" class="headerlink" title="找到请求模式"></a>找到请求模式</h3><p>返回Network标签页，观察该文件的<strong>请求头</strong>与<strong>请求参数</strong>，可以看出：请求头中主要有<strong>Cookies</strong>和<strong>User-Agent</strong>两部分，而请求参数中出现了显眼的<strong>pos</strong>参数。通过翻页测试，我们发现pos参数符合以下规律：</p>
<blockquote>
<p>第一页：pos = 0<br>第二页：pos = 20<br>第三页：pos = 40</p>
</blockquote>
<p>因此，我们可以得出以下结论</p>
<blockquote>
<p>pos = 20 * 页码数 - 20</p>
</blockquote>
<p>因此，我们接下来就将使用<strong>Selenium</strong>进行模拟登陆，并按照上述规律对文件进行获取。</p>
<h2 id="基于Selenium的数据获取"><a href="#基于Selenium的数据获取" class="headerlink" title="基于Selenium的数据获取"></a>基于Selenium的数据获取</h2><p>为了便于调试，我们先利用Selenium登陆QQ空间，并且对文件进行请求。然后，我们将请求的数据进行格式化存储。</p>
<h3 id="登陆"><a href="#登陆" class="headerlink" title="登陆"></a>登陆</h3><p>我们首先创建Selenium的webdriver实例，并用它打开QQ空间登陆界面，进入目标空间。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">qq_id = <span class="number">2074934525</span> <span class="comment"># Change it if necessary.</span></span><br><span class="line">login_url = <span class="string">'https://user.qzone.qq.com'</span></span><br><span class="line">target_url = <span class="string">'https://user.qzone.qq.com/&#123;&#125;/311'</span>.format(qq_id)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ini_driver</span><span class="params">()</span>:</span></span><br><span class="line">    driver = webdriver.Chrome()</span><br><span class="line">    <span class="keyword">return</span> driver</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    driver = ini_driver()</span><br><span class="line">    driver.get(login_url)</span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br><span class="line">    driver.get(target_url)</span><br></pre></td></tr></table></figure>
<h3 id="请求资源"><a href="#请求资源" class="headerlink" title="请求资源"></a>请求资源</h3><p>为了获取加载资源列表，我们需要调整Selenium的<strong>DesiredCapabilities</strong>特性，从而获得目标文件的请求细节。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.common.desired_capabilities <span class="keyword">import</span> DesiredCapabilities</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ini_driver</span><span class="params">()</span>:</span></span><br><span class="line">    caps = DesiredCapabilities.CHROME</span><br><span class="line">    caps[<span class="string">'loggingPrefs'</span>] = &#123;<span class="string">'performance'</span>: <span class="string">'ALL'</span>&#125;</span><br><span class="line">    driver = webdriver.Chrome(desired_capabilities=caps)</span><br><span class="line">    <span class="keyword">return</span> driver</span><br><span class="line"></span><br><span class="line">log = str(driver.get_log(<span class="string">'performance'</span>))</span><br></pre></td></tr></table></figure>
<p>通过分析请求，我们构造出请求的<strong>匹配模式</strong>，将完整的<strong>请求体</strong>匹配出来，并将完整请求拆分为 _prefix + page_pos + suffix_ 的模式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">file_prefix = <span class="string">r"https://user.qzone.qq.com/proxy/domain/taotao.qq.com/cgi-bin/emotion_cgi_msglist_v6"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_format</span><span class="params">(data:str)</span>:</span></span><br><span class="line">    pos = data.find(<span class="string">'pos='</span>)</span><br><span class="line">    prefix = file_prefix + data[:pos+<span class="number">4</span>]</span><br><span class="line">    suffix = data[pos+<span class="number">5</span>:]</span><br><span class="line">    <span class="keyword">return</span> (prefix,suffix)</span><br><span class="line"></span><br><span class="line">pattern = re.compile(<span class="string">r'"https://user.qzone.qq.com/proxy/domain/taotao.qq.com/cgi-bin/emotion_cgi_msglist_v6(.*?)"'</span>)</span><br><span class="line"></span><br><span class="line">data = re.findall(pattern,log)[<span class="number">0</span>]</span><br><span class="line">prefix,suffix = get_format(data)</span><br></pre></td></tr></table></figure>
<p>此时，我们即可使用如下方式获得某一页的说说内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">page_pos = str(<span class="number">0</span>)</span><br><span class="line">content_url = prefix + page_pos + suffix</span><br><span class="line">content = driver.get(content_url)</span><br></pre></td></tr></table></figure>
<h3 id="格式化与存储"><a href="#格式化与存储" class="headerlink" title="格式化与存储"></a>格式化与存储</h3><p>上一步提取出的<strong>content</strong>为原始的目标文件。我们需要将其格式化为符合<strong>json</strong>规则的代码，并将其存储在文件中。</p>
<p>我们先利用字符串切片，除去开头结尾的无关字符。剩余内容为符合json规则的字符串，可以使用<code>json.loads</code>将其转化为json类型。此外，所有的说说内容都存放在<code>msglist</code>字段中。我们将其提取出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_msg_list</span><span class="params">(content:str)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> json.loads(content[<span class="number">17</span>:<span class="number">-2</span>])[<span class="string">'msglist'</span>]</span><br></pre></td></tr></table></figure>
<p>接着，由于<code>msglist</code>字段中存在着大量的无关数据。我们用<code>msglist</code>字段中信息的有效部分构造<code>new_msg</code>，将它存放在字典中。</p>
<blockquote>
<p>因为每条说说的发送时间唯一，我们以说说的timestamp(时间戳)属性作为字典索引。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">msglist = dict()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_raw_msglist</span><span class="params">(raw_msglist:dict)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> raw_msglist <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">for</span> msg <span class="keyword">in</span> raw_msglist:</span><br><span class="line">            new_msg = dict()</span><br><span class="line">            new_msg[<span class="string">'content'</span>] = msg[<span class="string">'content'</span>]</span><br><span class="line">            new_msg[<span class="string">'commentlist'</span>] = list()</span><br><span class="line">            <span class="keyword">if</span> msg[<span class="string">'commentlist'</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">for</span> comment <span class="keyword">in</span> msg[<span class="string">'commentlist'</span>]:</span><br><span class="line">                    new_msg[<span class="string">'commentlist'</span>].append(</span><br><span class="line">                        &#123;</span><br><span class="line">                                <span class="string">'content'</span> : comment[<span class="string">'content'</span>],</span><br><span class="line">                                <span class="string">'time'</span> : comment[<span class="string">'create_time'</span>],</span><br><span class="line">                                <span class="string">'name'</span> : comment[<span class="string">'name'</span>]</span><br><span class="line">                        &#125;</span><br><span class="line">                    )</span><br><span class="line">            msglist[msg[<span class="string">'created_time'</span>]] = new_msg</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<p>此时，<code>msglist</code>即为我们需要的说说内容数据。我们将其保存在本地文件中。</p>
<blockquote>
<p>为了能够正常保存中文数据，我们应当用UTF-8编码写入文件，并且在<code>json.dumps</code>方法中增加<code>ensure_ascii=False</code>参数。</p>
</blockquote>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">"&#123;&#125;.json"</span>.format(qq_id),<span class="string">'w+'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(json.dumps(msglist,indent=<span class="number">4</span>,ensure_ascii=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure>
<p>通过遍历<code>page_pos</code>，我们即可完成对数据的自动获取工作。</p>
<h2 id="用Requests实现多进程获取"><a href="#用Requests实现多进程获取" class="headerlink" title="用Requests实现多进程获取"></a>用Requests实现多进程获取</h2><p>由于Selenium的特性，我们一次只能获取一页数据。这种单进程模式对数据获取速度产生了较大的限制。此外，基于可视页面的ChromeDriver对系统资源的占用也较多。虽然可以通过<strong>headless</strong>启动或换用<strong>PhantomJS</strong>进行优化，但我们决定采用<strong>Requests+Multiprocessing</strong>的方法实现对数据的多进程获取。</p>
<h3 id="构造Header"><a href="#构造Header" class="headerlink" title="构造Header"></a>构造Header</h3><p>在分析网页内容时，我们观察了请求<code>emotion_cgi_msglist_v6</code>时的Header格式。我们首先构造出header的<strong>User-Agent</strong>部分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">User_Agent = <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.108 Safari/537.36'</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span> : User_Agent</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>接着，我们对<strong>Cookies</strong>进行传递。我们利用<code>driver.get_cookies()</code>方法获得driver携带的所有cookie，并将其处理后保存为<code>qzone_cookies</code>字典。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">qzone_cookies = dict()</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> driver.get_cookies():</span><br><span class="line">    qzone_cookies[item[<span class="string">"name"</span>]] = item[<span class="string">"value"</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在Cookies保存完后，可用<code>driver.quit()</code>退出webdriver，减少资源占用。</p>
</blockquote>
<h3 id="构造请求方法"><a href="#构造请求方法" class="headerlink" title="构造请求方法"></a>构造请求方法</h3><p>为了便于用Multiprocessing进行多进程处理，我们先创建一个<code>Requests.session</code>，然后重写<code>get_msg_list</code>方法，将上一步中构造的Header与Cookies作为参数传递进去。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">session = requests.session()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_msg_list</span><span class="params">(url:str,headers,qzone_cookies)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> json.loads(session.get(url,headers=headers,cookies=qzone_cookies).text[<span class="number">17</span>:<span class="number">-2</span>])[<span class="string">'msglist'</span>]</span><br></pre></td></tr></table></figure>
<h3 id="配置进程池"><a href="#配置进程池" class="headerlink" title="配置进程池"></a>配置进程池</h3><p>接下来，我们创建Multiprocessing的<strong>进程池(Pool)</strong>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">process_number = 8</span><br><span class="line">pos_pool = multiprocessing.Pool(processes=process_number)</span><br></pre></td></tr></table></figure>
<p>为了便于自动分配进程，我们构造<code>url_list</code>为获取地址的列表。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">construct_url_list</span><span class="params">(prefix:str,suffix:str,times:int)</span>:</span></span><br><span class="line">    url_list = list()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,times):</span><br><span class="line">        url_list.append(prefix+str(i*<span class="number">20</span>)+suffix)</span><br><span class="line">    <span class="keyword">return</span> url_list</span><br><span class="line"></span><br><span class="line">page_number = <span class="number">10</span> <span class="comment"># Change it if necessary.</span></span><br><span class="line">url_list = construct_url_list(prefix,suffix,page_number)</span><br></pre></td></tr></table></figure>
<p>在前两项准备工作结束后，我们就可以对进程池进行任务指派了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for url in url_list:</span><br><span class="line">    pos_pool.apply_async(get_msg_list,args=(url,headers,qzone_cookies),callback=process_raw_msglist)</span><br><span class="line">print(&quot;Start&quot;)</span><br><span class="line">pos_pool.close()</span><br><span class="line">pos_pool.join()</span><br><span class="line">print(&apos;Done&apos;)</span><br></pre></td></tr></table></figure>
<p>进程池会自动协调内部的进程，为每一个进程分配一个任务（此处为获取<code>url</code>的文件数据，在格式化后存入<code>msglist</code>字典中），并在任务结束后分配新的任务，直到<code>url_list</code>被完全遍历。</p>
<p>对于进程数为8的进程池，每秒可以获取约8~10页，即150~200条说说内容。现在，主要的工作已经完成了。</p>
<h2 id="功能完善"><a href="#功能完善" class="headerlink" title="功能完善"></a>功能完善</h2><p>在完成了主要功能的制作后，我们对程序的功能进行完善。</p>
<h3 id="在登陆后自动跳转"><a href="#在登陆后自动跳转" class="headerlink" title="在登陆后自动跳转"></a>在登陆后自动跳转</h3><p>我们刚刚使用<code>sleep(5)</code>作为登陆延时。但是，跳转到目标空间应该在登陆后自动进行。为此，我们引入selenium的<strong>WebDriverWait</strong>功能，在登陆后（即网页标题变化为 _xxx.qzone.com_ 后）自动跳转至目标空间。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.common.desired_capabilities <span class="keyword">import</span> DesiredCapabilities</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    driver = ini_driver()</span><br><span class="line">    driver.get(login_url)</span><br><span class="line">    WebDriverWait(driver,<span class="number">60</span>).until(EC.title_contains(<span class="string">"qzone"</span>))</span><br><span class="line">    driver.get(target_url)</span><br></pre></td></tr></table></figure>
<h3 id="自动获取页面数量"><a href="#自动获取页面数量" class="headerlink" title="自动获取页面数量"></a>自动获取页面数量</h3><p>先前的程序中，<code>url_list</code>的大小需要手动输入。对于理想的程序，<code>url_list</code>的大小应为说说页面的实际数量。通过观察，我们主要到目标说说的数量存放于<code>emotion_cgi_msglist_v6</code>文件的<code>total</code>字段中。由于一页最多有20条说说，我们可以用说说总数算出页面的数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> ceil</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_total</span><span class="params">(url:str,headers,qzone_cookies)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> json.loads(session.get(url,headers=headers,cookies=qzone_cookies).text[<span class="number">17</span>:<span class="number">-2</span>])[<span class="string">'total'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">global</span> page_number</span><br><span class="line">page_number = <span class="number">0</span> <span class="comment"># Get all pages unless otherwise specified.</span></span><br><span class="line"><span class="keyword">if</span> page_number == <span class="number">0</span>:</span><br><span class="line">    page_number = ceil(get_total(prefix+<span class="string">"0"</span>+suffix,headers,qzone_cookies)/<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<h3 id="估计剩余时间"><a href="#估计剩余时间" class="headerlink" title="估计剩余时间"></a>估计剩余时间</h3><p>在获取一定数量的页面数据，我们可以大致计算出获取每个页面所需要的时间，并借此算出预估的剩余时间。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">global</span> counter</span><br><span class="line">counter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_raw_msglist</span><span class="params">(raw_msglist:dict)</span>:</span></span><br><span class="line">	<span class="keyword">if</span> raw_msglist <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># Some duplicate code are left out.</span></span><br><span class="line">        <span class="keyword">global</span> counter,page_number</span><br><span class="line">        counter += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> counter&gt;<span class="number">20</span>:</span><br><span class="line">            <span class="keyword">global</span> start_time</span><br><span class="line">            print(<span class="string">"&#123;:d&#125; of &#123;:d&#125; finished.(About &#123;:.3f&#125;s left.)"</span>.format(counter,page_number,calc_time(start_time)))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"&#123;:d&#125; of &#123;:d&#125; finished."</span>.format(counter,page_number))</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_time</span><span class="params">(start_time)</span>:</span></span><br><span class="line">    consumed_time = time()-start_time</span><br><span class="line">    <span class="keyword">global</span> counter,page_number</span><br><span class="line">    per_time = consumed_time/counter</span><br><span class="line">    <span class="keyword">return</span> (page_number-counter)*per_time</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># Some duplicate code are left out.</span></span><br><span class="line">    print(<span class="string">"Start"</span>)</span><br><span class="line">    start_time = time()</span><br></pre></td></tr></table></figure>
<h3 id="大文件分割"><a href="#大文件分割" class="headerlink" title="大文件分割"></a>大文件分割</h3><p>由于较大的数据集不便于网络传输，我们可以将生成的说说内容文件按一定的容量进行拆分。经过验证，40000条说说的大小约为30~40MB。以下给出拆分脚本的代码，供读者参考。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line">split_size = <span class="number">40000</span> <span class="comment"># Change it if necessary</span></span><br><span class="line">name = <span class="string">"NJU_BBQ"</span> <span class="comment"># Change it if necessary</span></span><br><span class="line"></span><br><span class="line">data_path = sys.path[<span class="number">0</span>] + <span class="string">"/data/"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(data_path + <span class="string">"&#123;&#125;.json"</span>.format(name),<span class="string">'r'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json_data = json.loads(f.read())</span><br><span class="line"></span><br><span class="line">new_data = dict()</span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> json_data:</span><br><span class="line">    new_data[index] = json_data[index]</span><br><span class="line">    <span class="keyword">if</span> len(new_data)&gt;split_size:</span><br><span class="line">        <span class="keyword">with</span> open(data_path + <span class="string">"&#123;&#125;_part_&#123;:d&#125;.json"</span>.format(name,count),<span class="string">'w+'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(json.dumps(new_data,indent=<span class="number">4</span>,ensure_ascii=<span class="literal">False</span>))</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        new_data = dict()</span><br><span class="line"><span class="keyword">if</span> count!=<span class="number">0</span>:</span><br><span class="line">    <span class="keyword">with</span> open(data_path + <span class="string">"&#123;&#125;_part_&#123;:d&#125;.json"</span>.format(name,count),<span class="string">'w+'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(json.dumps(new_data,indent=<span class="number">4</span>,ensure_ascii=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>本教程的完整项目代码已在Github开源。地址如下：<a href="https://github.com/EricZhu-42/QQ_Zone_Spider" target="_blank" rel="noopener">项目地址</a></p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/26/Functional-Programming-of-Python/" rel="next" title="Python中的函数式编程">
                <i class="fa fa-chevron-left"></i> Python中的函数式编程
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/07/31/Dense-Captioning/" rel="prev" title="Dense Captioning with Joint Inference and Visual Context">
                Dense Captioning with Joint Inference and Visual Context <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="EricZhu-42">
            
              <p class="site-author-name" itemprop="name">EricZhu-42</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">20</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">标签</span>
                  
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/EricZhu-42" title="GitHub &rarr; https://github.com/EricZhu-42" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#功能简介"><span class="nav-number">1.1.</span> <span class="nav-text">功能简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#环境需求"><span class="nav-number">1.2.</span> <span class="nav-text">环境需求</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#你将在这里看到"><span class="nav-number">2.</span> <span class="nav-text">你将在这里看到</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#你将不会在这里看到"><span class="nav-number">3.</span> <span class="nav-text">你将不会在这里看到</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关于思路的简单介绍"><span class="nav-number">4.</span> <span class="nav-text">关于思路的简单介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网页内容分析"><span class="nav-number">5.</span> <span class="nav-text">网页内容分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#找到资源文件"><span class="nav-number">5.1.</span> <span class="nav-text">找到资源文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#找到请求模式"><span class="nav-number">5.2.</span> <span class="nav-text">找到请求模式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于Selenium的数据获取"><span class="nav-number">6.</span> <span class="nav-text">基于Selenium的数据获取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#登陆"><span class="nav-number">6.1.</span> <span class="nav-text">登陆</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#请求资源"><span class="nav-number">6.2.</span> <span class="nav-text">请求资源</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#格式化与存储"><span class="nav-number">6.3.</span> <span class="nav-text">格式化与存储</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#用Requests实现多进程获取"><span class="nav-number">7.</span> <span class="nav-text">用Requests实现多进程获取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#构造Header"><span class="nav-number">7.1.</span> <span class="nav-text">构造Header</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#构造请求方法"><span class="nav-number">7.2.</span> <span class="nav-text">构造请求方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置进程池"><span class="nav-number">7.3.</span> <span class="nav-text">配置进程池</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#功能完善"><span class="nav-number">8.</span> <span class="nav-text">功能完善</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#在登陆后自动跳转"><span class="nav-number">8.1.</span> <span class="nav-text">在登陆后自动跳转</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自动获取页面数量"><span class="nav-number">8.2.</span> <span class="nav-text">自动获取页面数量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#估计剩余时间"><span class="nav-number">8.3.</span> <span class="nav-text">估计剩余时间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#大文件分割"><span class="nav-number">8.4.</span> <span class="nav-text">大文件分割</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#后记"><span class="nav-number">9.</span> <span class="nav-text">后记</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">EricZhu-42</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.1.0</div>




<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共26.2k字</span>
</div>

        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.0"></script>

  <script src="/js/motion.js?v=7.1.0"></script>



  
  


  <script src="/js/affix.js?v=7.1.0"></script>

  <script src="/js/schemes/pisces.js?v=7.1.0"></script>




  
  <script src="/js/scrollspy.js?v=7.1.0"></script>
<script src="/js/post-details.js?v=7.1.0"></script>



  


  <script src="/js/next-boot.js?v=7.1.0"></script>


  

  

  

  


  


  




  

  

  
  

  
  

  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
